{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression Cost Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Training Data for Classification\n",
    "In this section, training data for a classification problem is defined. The input features are stored in the array `X_train_classification`, and the corresponding labels are stored in the array `y_train_classification`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define training data for classification\n",
    "X_train_classification = np.array([[0.5, 1.5], [1, 1], [1.5, 0.5], [3, 0.5], [2, 2], [1, 2.5]])\n",
    "y_train_classification = np.array([0, 0, 0, 1, 1, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sigmoid Activation Function\n",
    "The function `sigmoid_function` implements the sigmoid activation function. It takes an input value (`z`) and returns the output of the sigmoid function (`g`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid_function(z):\n",
    "    \"\"\"\n",
    "    Sigmoid activation function.\n",
    "\n",
    "    Parameters:\n",
    "    - z: Input value.\n",
    "\n",
    "    Returns:\n",
    "    - g: Output of the sigmoid function.\n",
    "    \"\"\"\n",
    "    g = 1 / (1 + np.exp(-z))\n",
    "    return g"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression Cost Computation\n",
    "The function `compute_cost_logistic` computes the logistic regression cost using the sigmoid activation function. It takes input features matrix (`X`), binary output labels (`y`), weight, and bias as parameters and returns the computed logistic regression cost."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    "    <img src=\"1_loss_log.png\" alt=\"Linear Regression Cost\" />\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    "    <img src=\"2_loss_easy_log.png\" alt=\"Linear Regression Cost\" />\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    "    <img src=\"3_cost_log.png\" alt=\"Linear Regression Cost\" />\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost_logistic(X, y, weight, bias):\n",
    "    \"\"\"\n",
    "    Compute the logistic regression cost using the sigmoid activation function.\n",
    "\n",
    "    Parameters:\n",
    "    - X: Input features matrix as a NumPy array.\n",
    "    - y: Binary output labels (0 or 1) as a NumPy array.\n",
    "    - weight: Weight parameter of the logistic regression model.\n",
    "    - bias: Bias parameter of the logistic regression model.\n",
    "\n",
    "    Returns:\n",
    "    - cost: Logistic regression cost.\n",
    "    \"\"\"\n",
    "    m = X.shape[0]\n",
    "    cost = 0.0\n",
    "\n",
    "    # Calculate the logistic regression cost using sigmoid activation\n",
    "    for i in range(m):\n",
    "        z_i = np.dot(X[i], weight) + bias\n",
    "        f_wb_i = sigmoid_function(z_i)\n",
    "        cost += (-y[i] * np.log(f_wb_i)) - ((1 - y[i]) * np.log(1 - f_wb_i))\n",
    "\n",
    "    cost *= (1 / m)\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example Computation of Logistic Regression Cost\n",
    "The code demonstrates an example computation of the logistic regression cost using the function `compute_cost_logistic`. The input features (`X_train_classification`), binary output labels (`y_train_classification`), weight (`w_temp_example`), and bias (`b_temp_example`) are used for the calculation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3668667864055174\n"
     ]
    }
   ],
   "source": [
    "# Example computation of logistic regression cost\n",
    "w_temp_example = np.array([1, 1])\n",
    "b_temp_example = -3\n",
    "cost_example = compute_cost_logistic(X_train_classification, y_train_classification, w_temp_example, b_temp_example)\n",
    "print(cost_example)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
